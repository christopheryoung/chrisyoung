---
{date: '2008-08-10', explananda: '', title: 'Recently read: "Sway: The Irresistible
	Pull of Irrational Behavior"', tags: book_reviews}

---
<strong>Ori Brafman and Rom Brafman. <em>Sway: The Irresistible Pull of Irrational Behavior</em></strong>

<em>Sway</em> takes its place among a number of similar books now on the market which popularize recent psychological research on human irrationality (much of which goes back to the pioneering work of Kahneman and Tversky).  It's a short, breezy, but entertaining survey of the literature, written by a team of brothers, one a psychologist and the other an organizational expert.  The goal here is clearly to popularize, and I suspect at times the dumbing-down has gone a bit too far, but I nevertheless found the book a fun way to spend a couple of hours.

One rather central point that puzzled me had to do with the authors' understanding of the main term in their inquiry, "irrationality."  It might be that they explained at some point what they mean by this incredibly slippery term, and I just missed it.  But at different points in the book the term seemed to me to mean quite different things.

Here is one sort of irrationality discussed by the authors: It is well documented that we have a tendency to strongly bias original impressions, and to discount evidence relevant to a reconsideration of our original impression.  For example, draft pick order seems to play an outsized role in play time granted to professional basketball players, when much more sensible metrics are available for judging their performance  which actually seem to cut against decisions made on the basis of draft pick order.  Now, suppose you could sit down a coach and explain this to him.  You might be able to show that the coach's own goals are not well served by the way he makes use of the available evidence, and you could demonstrate that his decision-making process falls into well-known patterns of suboptimal decision-making.  And the coach might smack his forehead and say, "I've been irrational!"

Now consider a very different case, which supposedly also illustrates "irrationality."  Take two people, hand one of them $10, and explain the rules of the following game: The two are not to communicate in any way; they are strangers; they will not be playing this game again.  The player holding the $10 bill gets to make a single proposal to the other player about how to divide the money.  If the other player accepts the division of money, the two part with the proposed shares; if the other player rejects the division, neither player gets anything.

It is an interesting fact that most people offered less than $5 reject the offer, preferring to walk away with nothing.  (Actually, it is another interesting fact that individuals from different cultures apparently make very different choices when playing this game.)  Some economists and psychologists have argued that the choice is irrational, and Brafman and Brafman follow them in the description.  If you're offered $3, the thinking goes, you might as well take it, since $3 is more than $0.  It appears that people really don't like being shafted, and it matters enough to them to punish the other player that in order to impose the punishment they're willing to forfeit what they might have otherwise gained.

But notice that if this is irrational, it's clearly a different kind of irrationality from the one mentioned above.  The kind of irrationality mentioned above involves an agent's improper use of evidence to achieve the agent's own goals.  And once pointed out, it's the kind of mental habit that we might resolve to avoid in the future.  But I don't see how additional evidence or explanation could get people to reconsider walking away from $3.  The fact is, they don't like unfairness; it matters to them, as well as money; and in some cases, it matters to them more than money.  The preference for fairness is built into their own preference structure, and the preference for money is just one more preference within that preference structure alongside others.  Indeed this is why the decision doesn't strike me as necessarily irrational: walking away from the $3 may well maximize the agent's carefully considered and properly weighted preferences.

I should say that the subtitle of the book, suggesting that the pull of the irrational is <em>irresistible</em>, is unduly pessimistic.  In an epilogue, the authors quite reasonably point out that awareness of the different ways in which we fail to be fully rational might help us to make better decisions.  This seems to be true.  Indeed, it's at least half the appeal of books like <em>Sway</em>.


<h1>Comments</h1>


<br/>
<em>Author:</em> Steve Laniel
<br/><em>Date:</em> 2008-08-10

On the desire for fairness, in apparent (and *only* apparent) contradiction of one's rational goals, see Robert H. Frank's "Passions Within Reason."

In short: becoming known as the sort of person who will routinely violate his own short-term self-interest for the sake of his larger self-interest can be, in itself, rational. This is the same sort of game theory at play in mutually assured destruction: if my nation gets fired upon first, it has no purely self-interested reason to fire back; if we're going to get destroyed, how does it help us to destroy the other guy? But if we make it known that we will destroy the other guy no matter what, then the other guy will think twice about firing on us to begin with. That is: making it known that we'll act "irrationally" serves our own self-interest.

Love is another good example of this. If your partner knows that you're just staying with her until someone better comes along -- that you are the sort of person who maximizes his self-interest from moment to moment -- then you are unlikely to keep your partner for very long at all. You need to convince your partner that you will be systematically "irrational": that you will give up momentary pleasures for the long-term good of your relationship.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-10

Exactly.  There's that, but there's also just that fact that people might value a certain self-conception that rules out getting played for a chump, apart from any consequences.  Now perhaps that's not a rational thing to value, but if someone wants to claim that, I don't think we're having the same discussion we started out having.  The question of what ultimate ends are rational to value is entirely separate from the question of what ways to satisfy those ends are rational.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-10

Sorry.  To be clear: " . . .if someone wants to claim that [it's not a rational thing to value], I don't think . . ."
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Steve Laniel
<br/><em>Date:</em> 2008-08-10

Books ultimately sitting atop behavioral economics and its spawn are thick on the ground these days, it seems. I think now's the time for me to dive into Kahneman and Tversky's "Choices, Values, and Frames," which to all appearances is the locus classicus of that whole literature. ... Well, locus classicus in one sense, I guess. If you want to ask, "What do we do to overcome these systematic irrationalities and cognitive limitations?" then a book like Thaler and Sunstein's "Nudge" is probably the right place to look. Or Thaler's earlier masterpiece "The Winner's Curse"; my friend Nina, who studied under Kahneman at Princeton, told me that "Winner's Curse" is the book that Kahneman himself recommends to people who want an entr&eacute;e into the field.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-10

Oh, thank you very much.  All those books are (thanks, in part, to you) already on my reading list.  But it's useful to know that "Winner's Curse" is a good place to start.

I remember being puzzled by some of these issues back in 2001 when I started thinking and reading (just) a bit about game theory and rational choice theory.  I didn't get terribly far, but I did end up trying to put some of it into a simple <a href="http://chrisyoung.net/miser.6.html" rel="nofollow">game</a>.  Unfortunately, I don't think I fiddled with the rules long enough, and at this point I can't remember any longer if there was a wrinkle that made the whole game sort of incoherent.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-10

That is, I put some of the game theory stuff into a simple game.  Not the puzzlement.  My game artificially turned players in precisely the sort of rational maximizers that I found so strange in some of the models that theorists were using to understand actual behavior.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Steve Laniel
<br/><em>Date:</em> 2008-08-10

See also (can't...stop...self...recommending...books) "Simple Heuristics That Make Us Smart" by Gigerenzer, Todd et al. It sets itself up as very anti-Kahneman-and-Tversky, though a few years out the debate seems kind of arid to me. Gigerenzer wants to say that what Tversky and Kahneman see as failings in the human cognitive apparatus are actually helpful. "Ecological rationality" is their term: when compared to theoretical optima based on precise axioms, human cognitive abilities look fairly poor; but when compared to the highly variable and unpredictable world we face, they do quite well.

The debate looks arid because ... I dunno, both sides seem to agree on the data; they just differ on the interpretation. It's not as though Kahneman and Tversky are saying "Humans suck"; they're just gathering data and trying to put it together into an economics that has plausible psychological foundations. ("Prospect theory," I gather, is their name for one such economics.)

Then there's Herb Simon's classic "Sciences of the Artificial," which in some sense got the whole game going to begin with. Or Simon himself did, anyway. Keyword here is "bounded rationality": the recognition that as a bare mathematical fact, humans *cannot* be utility maximizers.

Okay, I'm done ... for now.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-10

Thanks again!  Will look these up too when I can.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> DC
<br/><em>Date:</em> 2008-08-11

Couldn't one also challenge the description of the basketball coach as "irrational"? Surely as between the "systematic irrationalities and cognitive limitations" (mentioned by Steve Laniel) he seems more the latter than the former, no?

Obviously if he thought picking players with the nicest hair was the route to victory this would be plain irrational, but the draft information is relevant, it's not a totally crazy calculation as far as information short-cuts go. So he's not irrational, he's just not as efficient at using the information available to him.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-11

Well, yeah, not totally crazy, but also not nearly as well suited to predicting performance as other metrics.  Perhaps not the very best example of confirmation bias, but it does seem to me to make sense to call it irrationality.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> DC
<br/><em>Date:</em> 2008-08-12

Ah, I now see that I completely failed to get the point of the basketball coach example - i.e. "we have a tendency to strongly bias original impressions". Not being au courant with such things it didn't occur to me that the coach is himsef the guy who picks the order of the draft.

Maybe what I was saying would be true if the coach who chose the draft dies/is fired/whatever and his successor priviliged the draft order as information.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-12

Oh, I hadn't thought about that.  I <em>imagine</em> that's the case, but I've now returned the book to the library and can't check it.  Oh to be rich, and be able to buy books again.  But <em>if</em> I recall correctly, this actually wasn't crucial.  It was more this sort of thing: "Oh that dude <em>must</em> be good, since he was high up in the draft order."  And armed with that thought you go on to discount other more obvious and relevant metrics - which are precisely the metrics you might well have realized are important if you hadn't already fixated on the draft order.  And that's the kind of thought you can have whether you're the one who did the picking or a replacement coach or just a spectator.
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> ben wolfson
<br/><em>Date:</em> 2008-08-13

Your quibble with the book, and the conversation with Laniel (obviously "you" here is Chris), seem like an exercise in unilluminating gotcha-ing. The way you're making the objection, you're basically agreeing that rationality = preference satisfaction, and just pointing out that someone might have more preferences than just the immediate maximization of his wealth, either because he's got preferences involving fairness or because he knows that acting in a certain fashion will maximize his long-term gains. Well, sure. But obviously this is not a deep point; not, anyway, if you're interested in rationality, rather than how to be conniving.  So all Brafman and Brafman would really need to rehabilitate their claim that rejecting any amount under $5 is irrational is to add some proviso like "insofar as people want money, this behavior is irrational".

A more interesting criticism would take aim at the assumptions that the desire (principle?) not to be made a chump is just another preference whose satisfaction is simultaneously to be solved for, and that rationality consists in performing such operations.

En garde!
<br/>
<br/>

*******************************************************************************



<br/>
<em>Author:</em> Chris
<br/><em>Date:</em> 2008-08-13

Ben,

Well, I don't think I meant it to be a point of massive world-historical significance.  Still, I've come across enough smug "this shows people are irrational without qualification" claims in my time (and surely you have too?) to find the point worth making.  If the authors' had wanted to add the proviso you suggest they could have; they didn't, I think, because it would have thrown a wrench in their breezy survey of all the ways that we're irrational, ways that they don't bother to qualify in the manner you suggest.  The way the book goes is: "Here's a way we're irrational.  Woah!  You'd sure want to avoid that!  Here's another way!  Woah!  You'd clearly want to look out for that!"  If they interrupted this with, "Here's a way that we're irrational, assuming that we ignore an important aspect of what people clearly care about" - well, then, I think that wouldn't fit well with the rest of the discussion, because there's no reason given for wanting to ignore this important aspect of what we care about.

So although I agree that I'm hardly making a <em>deep</em> point, I disagree that it isn't worth making - it concerns an equivocation on the central term in the book.

As for your more interesting criticism, yes, yes, indeed, it is a more interesting criticism.

Detente?
<br/>
<br/>

*******************************************************************************
